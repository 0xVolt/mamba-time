{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install tensorflow[and-cuda]==2.15.0.post1 transformers==4.36.2 einops==0.7.0 datasets==2.16.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-14T12:21:31.404791Z","iopub.execute_input":"2024-08-14T12:21:31.405259Z","iopub.status.idle":"2024-08-14T12:24:34.770536Z","shell.execute_reply.started":"2024-08-14T12:21:31.405225Z","shell.execute_reply":"2024-08-14T12:24:34.769403Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.15.0.post1 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m987.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting einops==0.7.0\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting datasets==2.16.1\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.23.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2.32.3)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (4.66.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.6)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.9.1)\nCollecting nvidia-cublas-cu12==12.2.5.6 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.2.142 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.0.8.103 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.3.141 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.16.5 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1)\n  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.42.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (2024.7.4)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.0.3)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1) (3.2.2)\nDownloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl (417.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.8/417.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl (13.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (23.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (845 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.8/845.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl (98.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl (124.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl (195.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, keras, fsspec, einops, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tokenizers, nvidia-cusolver-cu12, transformers, datasets, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.5.0\n    Uninstalling fsspec-2024.5.0:\n      Successfully uninstalled fsspec-2024.5.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.20.0\n    Uninstalling datasets-2.20.0:\n      Successfully uninstalled datasets-2.20.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ngcsfs 2024.5.0 requires fsspec==2024.5.0, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ns3fs 2024.5.0 requires fsspec==2024.5.0.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.1 dill-0.3.7 einops-0.7.0 fsspec-2023.10.0 keras-2.15.0 multiprocess-0.70.15 nvidia-cublas-cu12-12.2.5.6 nvidia-cuda-cupti-cu12-12.2.142 nvidia-cuda-nvcc-cu12-12.2.140 nvidia-cuda-nvrtc-cu12-12.2.140 nvidia-cuda-runtime-cu12-12.2.140 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.8.103 nvidia-curand-cu12-10.3.3.141 nvidia-cusolver-cu12-11.5.2.141 nvidia-cusparse-cu12-12.1.2.141 nvidia-nccl-cu12-2.16.5 nvidia-nvjitlink-cu12-12.2.140 tensorflow-2.15.0.post1 tokenizers-0.15.2 transformers-4.36.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\n\nfrom dataclasses import dataclass\nfrom einops import rearrange, repeat\nfrom typing import Union\n\nfrom transformers import AutoTokenizer\n\nimport datasets\nimport math\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:34.772455Z","iopub.execute_input":"2024-08-14T12:24:34.772770Z","iopub.status.idle":"2024-08-14T12:24:52.780691Z","shell.execute_reply.started":"2024-08-14T12:24:34.772740Z","shell.execute_reply":"2024-08-14T12:24:52.779889Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-14 12:24:38.911188: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-14 12:24:38.911242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-14 12:24:38.913131: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"max_seq_length = 512","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:52.781821Z","iopub.execute_input":"2024-08-14T12:24:52.782369Z","iopub.status.idle":"2024-08-14T12:24:52.786504Z","shell.execute_reply.started":"2024-08-14T12:24:52.782342Z","shell.execute_reply":"2024-08-14T12:24:52.785584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ModelArgs:\n    model_input_dims: int = 64\n    model_states: int = 64\n    projection_expand_factor: int = 2\n    conv_kernel_size: int = 4\n    delta_t_min: float = 0.001\n    delta_t_max: float = 0.1\n    delta_t_scale: float = 0.1\n    delta_t_init_floor: float = 1e-4\n    conv_use_bias: bool = True\n    dense_use_bias: bool = False\n    layer_id: int = -1\n    seq_length: int = max_seq_length\n    num_layers: int = 5\n    dropout_rate: float = 0.2\n    use_lm_head: float = False\n    num_classes: int = None\n    vocab_size: int = None\n    final_activation = None\n    loss: Union[str, keras.losses.Loss] = None\n    optimizer: Union[str, keras.optimizers.Optimizer] = keras.optimizers.AdamW()\n    metrics = ['accuracy']\n\n    def __post_init__(self):\n        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n\n        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n        if self.layer_id == -1:\n            self.layer_id = np.round(np.random.randint(0, 1000), 4)\n\n        if self.vocab_size == None:\n            raise ValueError(\"vocab size cannot be none\")\n\n        if self.use_lm_head:\n            self.num_classes=self.vocab_size\n        else:\n            if self.num_classes == None:\n                raise ValueError(f'num classes cannot be {self.num_classes}')\n\n            if self.num_classes == 1:\n                self.final_activation = 'sigmoid'\n            else:\n                self.final_activation = 'softmax'\n\n        if self.loss == None:\n            raise ValueError(f\"loss cannot be {self.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:52.788624Z","iopub.execute_input":"2024-08-14T12:24:52.788897Z","iopub.status.idle":"2024-08-14T12:24:53.507808Z","shell.execute_reply.started":"2024-08-14T12:24:52.788874Z","shell.execute_reply":"2024-08-14T12:24:53.506846Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\nvocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:53.509234Z","iopub.execute_input":"2024-08-14T12:24:53.509826Z","iopub.status.idle":"2024-08-14T12:24:54.222880Z","shell.execute_reply.started":"2024-08-14T12:24:53.509797Z","shell.execute_reply":"2024-08-14T12:24:54.222105Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b4643d6adc48f6b0040d1d99140ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"835d28571165430cb5b475d088038b1a"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def selective_scan(u, delta, A, B, C, D):\n    # first step of A_bar = exp(ΔA), i.e., ΔA\n    dA = tf.einsum('bld,dn->bldn', delta, A) \n    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n    \n    dA_cumsum = tf.pad(\n        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n    \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n    \n    # Cumulative sum along all the input tokens, parallel prefix sum, \n    # calculates dA for all the input tokens parallely\n    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)  \n\n    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n    dA_cumsum = tf.exp(dA_cumsum)  \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n\n    x = dB_u * dA_cumsum\n    # 1e-12 to avoid division by 0\n    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12) \n\n    y = tf.einsum('bldn,bln->bld', x, C)\n    \n    return y + u * D ","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:54.224193Z","iopub.execute_input":"2024-08-14T12:24:54.224945Z","iopub.status.idle":"2024-08-14T12:24:54.232605Z","shell.execute_reply.started":"2024-08-14T12:24:54.224908Z","shell.execute_reply":"2024-08-14T12:24:54.231758Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MambaBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        args = modelargs\n        self.layer_id = modelargs.layer_id\n\n        self.in_projection = layers.Dense(\n            args.model_internal_dim * 2, \n            input_shape=(args.model_input_dims,), use_bias=False)\n\n        self.conv1d = layers.Conv1D(\n            filters=args.model_internal_dim,\n            use_bias=args.conv_use_bias,\n            kernel_size=args.conv_kernel_size,\n            groups=args.model_internal_dim,\n            data_format='channels_first',\n            padding='causal'\n        )\n\n        # this layer takes in current token 'x' \n        # and outputs the input-specific Δ, B, C (according to S6)\n        self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n\n        # this layer projects Δ from delta_t_rank to the mamba internal \n        # dimension\n        self.delta_t_projection = layers.Dense(args.model_internal_dim, \n                                               input_shape=(args.delta_t_rank,), use_bias=True)\n\n        self.A = repeat(\n                tf.range(1, args.model_states+1, dtype=tf.float32), \n                'n -> d n', d=args.model_internal_dim)\n\n        self.A_log = tf.Variable(\n                tf.math.log(self.A), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_A_log_{args.layer_id}\")\n\n        self.D = tf.Variable(\n                np.ones(args.model_internal_dim), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_D_{args.layer_id}\")\n\n        self.out_projection = layers.Dense(\n                args.model_input_dims, \n                input_shape=(args.model_internal_dim,), \n                use_bias=args.dense_use_bias)\n\n    def call(self, x):\n        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n        Official Implementation:\n            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n\n        (batch_size, seq_len, dimension) = x.shape\n\n        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n        (x, res) = tf.split(x_and_res, \n                            [self.args.model_internal_dim, \n                             self.args.model_internal_dim], axis=-1)\n        \n        x = rearrange(x, 'b l d_in -> b d_in l')\n        x = self.conv1d(x)[:, :, :seq_len]\n        x = rearrange(x, 'b d_in l -> b l d_in')\n        \n        x = tf.nn.swish(x)\n        y = self.ssm(x)\n        y = y * tf.nn.swish(res)\n        return self.out_projection(y)\n    \n    def ssm(self, x):\n        \"\"\"Runs the SSM. See:\n            - Algorithm 2 in Section 3.2 in the Mamba paper\n            - run_SSM(A, B, C, u) in The Annotated S4\n            Official Implementation:\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n        (d_in, n) = self.A_log.shape\n\n        # Compute ∆ A B C D, the state space parameters.\n        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n        #                                  and is why Mamba is called **selective** state spaces)\n\n        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n        D = tf.cast(self.D, tf.float32)\n\n        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n\n        (delta, B, C) = tf.split(\n                x_dbl, \n                num_or_size_splits=[self.args.delta_t_rank, n, n], \n                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n\n        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n\n        return selective_scan(x, delta, A, B, C, D)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:54.234083Z","iopub.execute_input":"2024-08-14T12:24:54.234398Z","iopub.status.idle":"2024-08-14T12:24:54.254531Z","shell.execute_reply.started":"2024-08-14T12:24:54.234374Z","shell.execute_reply":"2024-08-14T12:24:54.253726Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        self.mixer = MambaBlock(modelargs)\n        self.norm = layers.LayerNormalization(epsilon=1e-5)\n\n    def call(self, x):\n        \"\"\"\n        Official Implementation:\n            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n            \n            Note: the official repo chains residual blocks that look like\n                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n            where the first Add is a no-op. This is purely for performance reasons as this\n            allows them to fuse the Add->Norm.\n\n            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n            \n        \"\"\"\n        return self.mixer(self.norm(x)) + x","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:54.255760Z","iopub.execute_input":"2024-08-14T12:24:54.256095Z","iopub.status.idle":"2024-08-14T12:24:54.273097Z","shell.execute_reply.started":"2024-08-14T12:24:54.256063Z","shell.execute_reply":"2024-08-14T12:24:54.272395Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def init_model(args: ModelArgs):\n    input_layer = layers.Input(shape=(args.seq_length,), name='input_ids')\n    x = layers.Embedding(args.vocab_size, args.model_input_dims, input_length=args.seq_length)(input_layer)\n\n    for i in range(args.num_layers):\n        x = ResidualBlock(args, name=f\"Residual_{i}\")(x)\n        x = layers.Dropout(args.dropout_rate)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n    if not args.use_lm_head: # use flatten only if we are using the model as an LM\n        x = layers.Flatten()(x)\n    x = layers.Dense(1024, activation=tf.nn.gelu)(x)\n    output_layer = layers.Dense(args.num_classes, activation=args.final_activation)(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='MambaTimeModel')\n    model.compile(\n        loss=args.loss,\n        optimizer=args.optimizer,\n        metrics=args.metrics\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:54.274516Z","iopub.execute_input":"2024-08-14T12:24:54.274899Z","iopub.status.idle":"2024-08-14T12:24:54.291995Z","shell.execute_reply.started":"2024-08-14T12:24:54.274869Z","shell.execute_reply":"2024-08-14T12:24:54.291265Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"args = ModelArgs(\n    model_input_dims=max_seq_length,\n    model_states=32,\n    num_layers=12,\n    dropout_rate=0.2,\n    vocab_size=vocab_size,\n    num_classes=1,\n    loss='binary_crossentropy',\n)\nmodel = init_model(args)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:54.294983Z","iopub.execute_input":"2024-08-14T12:24:54.295382Z","iopub.status.idle":"2024-08-14T12:24:58.490633Z","shell.execute_reply.started":"2024-08-14T12:24:54.295347Z","shell.execute_reply":"2024-08-14T12:24:58.489515Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"MambaTimeModel\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_ids (InputLayer)      [(None, 512)]             0         \n                                                                 \n embedding (Embedding)       (None, 512, 512)          25730048  \n                                                                 \n Residual_0 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout (Dropout)           (None, 512, 512)          0         \n                                                                 \n Residual_1 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_1 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_2 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_2 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_3 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_3 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_4 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_4 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_5 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_5 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_6 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_6 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_7 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_7 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_8 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_8 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_9 (ResidualBlock)  (None, 512, 512)          1744896   \n                                                                 \n dropout_9 (Dropout)         (None, 512, 512)          0         \n                                                                 \n Residual_10 (ResidualBlock  (None, 512, 512)          1744896   \n )                                                               \n                                                                 \n dropout_10 (Dropout)        (None, 512, 512)          0         \n                                                                 \n Residual_11 (ResidualBlock  (None, 512, 512)          1744896   \n )                                                               \n                                                                 \n dropout_11 (Dropout)        (None, 512, 512)          0         \n                                                                 \n layer_normalization_12 (La  (None, 512, 512)          1024      \n yerNormalization)                                               \n                                                                 \n flatten (Flatten)           (None, 262144)            0         \n                                                                 \n dense_48 (Dense)            (None, 1024)              268436480 \n                                                                 \n dense_49 (Dense)            (None, 1)                 1025      \n                                                                 \n=================================================================\nTotal params: 315107329 (1.17 GB)\nTrainable params: 315107329 (1.17 GB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom tqdm import tqdm\n\ndataset = load_dataset(\"neuralwork/fashion-style-instruct\", split=\"train\")\ndataset = dataset.train_test_split(test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:24:58.491746Z","iopub.execute_input":"2024-08-14T12:24:58.492068Z","iopub.status.idle":"2024-08-14T12:25:00.368711Z","shell.execute_reply.started":"2024-08-14T12:24:58.492018Z","shell.execute_reply":"2024-08-14T12:25:00.367913Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/882 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e400fcebdbca4aa48b78238615221a81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.64M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff60e76d5f442a6a130fef622cbbeab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3193 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccddeb26dde4d97bc253acb61fbeef0"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.369779Z","iopub.execute_input":"2024-08-14T12:25:00.370144Z","iopub.status.idle":"2024-08-14T12:25:00.376680Z","shell.execute_reply.started":"2024-08-14T12:25:00.370103Z","shell.execute_reply":"2024-08-14T12:25:00.375898Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input', 'completion', 'context'],\n        num_rows: 2235\n    })\n    test: Dataset({\n        features: ['input', 'completion', 'context'],\n        num_rows: 958\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token \nEOS_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.378431Z","iopub.execute_input":"2024-08-14T12:25:00.378965Z","iopub.status.idle":"2024-08-14T12:25:00.393241Z","shell.execute_reply.started":"2024-08-14T12:25:00.378928Z","shell.execute_reply":"2024-08-14T12:25:00.392212Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}]},{"cell_type":"code","source":"alpacaFormatString = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Context:\n{}\n\n### Input:\n{}\n\n### Completion:\n{}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.394354Z","iopub.execute_input":"2024-08-14T12:25:00.394617Z","iopub.status.idle":"2024-08-14T12:25:00.404834Z","shell.execute_reply.started":"2024-08-14T12:25:00.394594Z","shell.execute_reply":"2024-08-14T12:25:00.404154Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Define the function to create the new 'text' column\ndef formatDatasetAlpaca(sample):\n    context = sample['context']\n    inputText = sample['input']\n    completion = sample['completion']\n    \n    text = alpacaFormatString.format(context, inputText, completion) + EOS_TOKEN\n    sample['text'] = text\n    \n    return sample\n\n# Apply the function to the dataset\ndataset = dataset.map(formatDatasetAlpaca)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.405699Z","iopub.execute_input":"2024-08-14T12:25:00.405945Z","iopub.status.idle":"2024-08-14T12:25:00.972652Z","shell.execute_reply.started":"2024-08-14T12:25:00.405923Z","shell.execute_reply":"2024-08-14T12:25:00.971767Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2235 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08212dfa618548aeb984de5430e1be16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/958 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890dca34471e48f49c594c94efdeb980"}},"metadata":{}}]},{"cell_type":"code","source":"import pprint\npprint.pprint(dataset['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.973671Z","iopub.execute_input":"2024-08-14T12:25:00.973943Z","iopub.status.idle":"2024-08-14T12:25:00.982592Z","shell.execute_reply.started":"2024-08-14T12:25:00.973918Z","shell.execute_reply":"2024-08-14T12:25:00.981712Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'completion': \"For a work/office event, it's important to still look \"\n               'professional while embracing your personal style and body '\n               'type. Here are five outfit combinations that will suit your '\n               'preferences and make you feel confident:\\n'\n               '\\n'\n               '1. Outfit: Dark Wash Stretch Jeans\\n'\n               '\\n'\n               '- Top: A fitted, button-down shirt in a solid color (like navy '\n               'or white) that accentuates your muscular build.\\n'\n               '- Bottom: Dark wash stretch jeans that emphasize your curves '\n               'without being tight.\\n'\n               '- Shoes: A pair of black or brown leather loafers for a '\n               'polished look.\\n'\n               '- Accessories: A sleek leather belt and a simple wristwatch to '\n               'add subtle sophistication.\\n'\n               '\\n'\n               '2. Outfit: Dressy Chinos\\n'\n               '\\n'\n               '- Top: A plaid or patterned short-sleeve shirt with a relaxed '\n               'fit, tucked into the chinos.\\n'\n               '- Bottom: Tailored chinos in a complementary color, like gray '\n               'or khaki.\\n'\n               '- Shoes: Opt for sleek black or brown leather oxford shoes.\\n'\n               '- Accessories: A patterned pocket square in a matching color '\n               'scheme and a minimalist bracelet.\\n'\n               '\\n'\n               '3. Outfit: Tailored Suit\\n'\n               '\\n'\n               '- Top: A well-fitted suit jacket in a darker shade, like navy '\n               'or charcoal gray, that highlights your shoulders and chest.\\n'\n               '- Bottom: Match the suit jacket with tailored suit pants.\\n'\n               '- Shirt: A crisp white or light blue dress shirt for a clean '\n               'look.\\n'\n               '- Shoes: Classic black leather dress shoes.\\n'\n               '- Accessories: A patterned tie with a touch of color, pocket '\n               'square, and a stylish leather watch.\\n'\n               '\\n'\n               '4. Outfit: Smart Casual\\n'\n               '\\n'\n               '- Top: A slim-fit long-sleeve shirt in a trendy print or '\n               'pattern, like a small floral or abstract design.\\n'\n               '- Bottom: Dark wash slim-fit jeans that provide comfort and '\n               'complement your body type.\\n'\n               '- Shoes: Pair the outfit with brown suede boots for a '\n               'fashionable yet relaxed look.\\n'\n               '- Accessories: A leather belt with a stylish buckle and a '\n               'statement watch to complete the outfit.\\n'\n               '\\n'\n               '5. Outfit: Business Casual\\n'\n               '\\n'\n               '- Top: A well-fitted polo shirt in a solid color, like navy or '\n               'burgundy, to showcase your upper body.\\n'\n               '- Bottom: Comfortable stretch dress pants in a neutral color, '\n               'such as charcoal gray or black.\\n'\n               '- Shoes: Opt for brown leather loafers for a professional yet '\n               'comfortable footwear choice.\\n'\n               '- Accessories: A sleek leather belt, a minimalist lapel pin, '\n               'and a stylish pair of sunglasses (if appropriate) for added '\n               'flair.\\n'\n               '\\n'\n               'Remember, these outfit suggestions are meant to guide you, but '\n               'always feel free to adapt them based on your personal style '\n               'preferences and the dress code of the event.',\n 'context': \"I'm going to a work / office event.\",\n 'input': \"I'm a short, curvy man with a muscular build. I opt for relaxed, \"\n          'comfortable clothing like stretch jeans and loose shirts that '\n          'accommodate my frame.',\n 'text': 'Below is an instruction that describes a task, paired with an input '\n         'that provides further context. Write a response that appropriately '\n         'completes the request.\\n'\n         '\\n'\n         '### Context:\\n'\n         \"I'm going to a work / office event.\\n\"\n         '\\n'\n         '### Input:\\n'\n         \"I'm a short, curvy man with a muscular build. I opt for relaxed, \"\n         'comfortable clothing like stretch jeans and loose shirts that '\n         'accommodate my frame.\\n'\n         '\\n'\n         '### Completion:\\n'\n         \"For a work/office event, it's important to still look professional \"\n         'while embracing your personal style and body type. Here are five '\n         'outfit combinations that will suit your preferences and make you '\n         'feel confident:\\n'\n         '\\n'\n         '1. Outfit: Dark Wash Stretch Jeans\\n'\n         '\\n'\n         '- Top: A fitted, button-down shirt in a solid color (like navy or '\n         'white) that accentuates your muscular build.\\n'\n         '- Bottom: Dark wash stretch jeans that emphasize your curves without '\n         'being tight.\\n'\n         '- Shoes: A pair of black or brown leather loafers for a polished '\n         'look.\\n'\n         '- Accessories: A sleek leather belt and a simple wristwatch to add '\n         'subtle sophistication.\\n'\n         '\\n'\n         '2. Outfit: Dressy Chinos\\n'\n         '\\n'\n         '- Top: A plaid or patterned short-sleeve shirt with a relaxed fit, '\n         'tucked into the chinos.\\n'\n         '- Bottom: Tailored chinos in a complementary color, like gray or '\n         'khaki.\\n'\n         '- Shoes: Opt for sleek black or brown leather oxford shoes.\\n'\n         '- Accessories: A patterned pocket square in a matching color scheme '\n         'and a minimalist bracelet.\\n'\n         '\\n'\n         '3. Outfit: Tailored Suit\\n'\n         '\\n'\n         '- Top: A well-fitted suit jacket in a darker shade, like navy or '\n         'charcoal gray, that highlights your shoulders and chest.\\n'\n         '- Bottom: Match the suit jacket with tailored suit pants.\\n'\n         '- Shirt: A crisp white or light blue dress shirt for a clean look.\\n'\n         '- Shoes: Classic black leather dress shoes.\\n'\n         '- Accessories: A patterned tie with a touch of color, pocket square, '\n         'and a stylish leather watch.\\n'\n         '\\n'\n         '4. Outfit: Smart Casual\\n'\n         '\\n'\n         '- Top: A slim-fit long-sleeve shirt in a trendy print or pattern, '\n         'like a small floral or abstract design.\\n'\n         '- Bottom: Dark wash slim-fit jeans that provide comfort and '\n         'complement your body type.\\n'\n         '- Shoes: Pair the outfit with brown suede boots for a fashionable '\n         'yet relaxed look.\\n'\n         '- Accessories: A leather belt with a stylish buckle and a statement '\n         'watch to complete the outfit.\\n'\n         '\\n'\n         '5. Outfit: Business Casual\\n'\n         '\\n'\n         '- Top: A well-fitted polo shirt in a solid color, like navy or '\n         'burgundy, to showcase your upper body.\\n'\n         '- Bottom: Comfortable stretch dress pants in a neutral color, such '\n         'as charcoal gray or black.\\n'\n         '- Shoes: Opt for brown leather loafers for a professional yet '\n         'comfortable footwear choice.\\n'\n         '- Accessories: A sleek leather belt, a minimalist lapel pin, and a '\n         'stylish pair of sunglasses (if appropriate) for added flair.\\n'\n         '\\n'\n         'Remember, these outfit suggestions are meant to guide you, but '\n         'always feel free to adapt them based on your personal style '\n         'preferences and the dress code of the event.<|endoftext|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:00.983709Z","iopub.execute_input":"2024-08-14T12:25:00.984461Z","iopub.status.idle":"2024-08-14T12:25:01.077337Z","shell.execute_reply.started":"2024-08-14T12:25:00.984421Z","shell.execute_reply":"2024-08-14T12:25:01.076350Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input', 'completion', 'context', 'text'],\n        num_rows: 2235\n    })\n    test: Dataset({\n        features: ['input', 'completion', 'context', 'text'],\n        num_rows: 958\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Extract the \"text\" column for train and test datasets\ntrain_texts = dataset['train']['text']\ntest_texts = dataset['test']['text']","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:01.078932Z","iopub.execute_input":"2024-08-14T12:25:01.079390Z","iopub.status.idle":"2024-08-14T12:25:01.099610Z","shell.execute_reply.started":"2024-08-14T12:25:01.079357Z","shell.execute_reply":"2024-08-14T12:25:01.098744Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Tokenize the texts\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_seq_length)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:01.100768Z","iopub.execute_input":"2024-08-14T12:25:01.101168Z","iopub.status.idle":"2024-08-14T12:25:03.436750Z","shell.execute_reply.started":"2024-08-14T12:25:01.101135Z","shell.execute_reply":"2024-08-14T12:25:03.435960Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Convert lists to tensors\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings)\n))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings)\n))\n\n# Batch and shuffle the datasets\nBATCH_SIZE = 32\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:03.437963Z","iopub.execute_input":"2024-08-14T12:25:03.438600Z","iopub.status.idle":"2024-08-14T12:25:13.042459Z","shell.execute_reply.started":"2024-08-14T12:25:03.438565Z","shell.execute_reply":"2024-08-14T12:25:13.041628Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=test_dataset, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T12:25:37.913061Z","iopub.execute_input":"2024-08-14T12:25:37.913758Z","iopub.status.idle":"2024-08-14T12:25:37.983219Z","shell.execute_reply.started":"2024-08-14T12:25:37.913726Z","shell.execute_reply":"2024-08-14T12:25:37.981879Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparseCategoricalCrossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","\u001b[0;31mTypeError\u001b[0m: Model.fit() got an unexpected keyword argument 'loss'"],"ename":"TypeError","evalue":"Model.fit() got an unexpected keyword argument 'loss'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}