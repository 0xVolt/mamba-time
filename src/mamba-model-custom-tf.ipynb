{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n# %pip install tensorflow[and-cuda]==2.15.0.post1 transformers==4.36.2 einops==0.7.0 datasets==2.16.1\n%pip install transformers==4.36.2 einops==0.7.0 datasets==2.16.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-15T20:00:50.089877Z","iopub.execute_input":"2024-08-15T20:00:50.091094Z","iopub.status.idle":"2024-08-15T20:01:26.954232Z","shell.execute_reply.started":"2024-08-15T20:00:50.091051Z","shell.execute_reply":"2024-08-15T20:01:26.952726Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting einops==0.7.0\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting datasets==2.16.1\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2.32.3)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (4.66.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.6)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (2024.7.4)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\nDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, einops, dill, multiprocess, tokenizers, transformers, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.5.0\n    Uninstalling fsspec-2024.5.0:\n      Successfully uninstalled fsspec-2024.5.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.20.0\n    Uninstalling datasets-2.20.0:\n      Successfully uninstalled datasets-2.20.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngcsfs 2024.5.0 requires fsspec==2024.5.0, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ns3fs 2024.5.0 requires fsspec==2024.5.0.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.1 dill-0.3.7 einops-0.7.0 fsspec-2023.10.0 multiprocess-0.70.15 tokenizers-0.15.2 transformers-4.36.2\nNote: you may need to restart the kernel to use updated packages.\nCPU times: user 813 ms, sys: 157 ms, total: 970 ms\nWall time: 36.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\n\nfrom dataclasses import dataclass\nfrom einops import rearrange, repeat\nfrom typing import Union\n\nfrom transformers import AutoTokenizer\n\nimport datasets\nimport math\nimport numpy as np\nimport pprint","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:26.956729Z","iopub.execute_input":"2024-08-15T20:01:26.957137Z","iopub.status.idle":"2024-08-15T20:01:51.735402Z","shell.execute_reply.started":"2024-08-15T20:01:26.957101Z","shell.execute_reply":"2024-08-15T20:01:51.733863Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-15 20:01:32.287170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 20:01:32.287333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 20:01:32.469904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"max_seq_length = 512","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:51.737033Z","iopub.execute_input":"2024-08-15T20:01:51.738002Z","iopub.status.idle":"2024-08-15T20:01:51.745030Z","shell.execute_reply.started":"2024-08-15T20:01:51.737930Z","shell.execute_reply":"2024-08-15T20:01:51.743173Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ModelArgs:\n    model_input_dims: int = 64\n    model_states: int = 64\n    projection_expand_factor: int = 2\n    conv_kernel_size: int = 4\n    delta_t_min: float = 0.001\n    delta_t_max: float = 0.1\n    delta_t_scale: float = 0.1\n    delta_t_init_floor: float = 1e-4\n    conv_use_bias: bool = True\n    dense_use_bias: bool = False\n    layer_id: int = -1\n    seq_length: int = max_seq_length\n    num_layers: int = 5\n    dropout_rate: float = 0.2\n    use_lm_head: float = True\n    num_classes: int = None\n    vocab_size: int = None\n    final_activation = None\n    loss: Union[str, keras.losses.Loss] = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    optimizer: Union[str, keras.optimizers.Optimizer] = keras.optimizers.AdamW()\n    metrics = ['accuracy']\n\n    def __post_init__(self):\n        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n\n        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n        if self.layer_id == -1:\n            self.layer_id = np.round(np.random.randint(0, 1000), 4)\n\n        if self.vocab_size == None:\n            raise ValueError(\"vocab size cannot be none\")\n\n        if self.use_lm_head:\n            self.num_classes=self.vocab_size\n        else:\n            if self.num_classes == None:\n                raise ValueError(f'num classes cannot be {self.num_classes}')\n\n            if self.num_classes == 1:\n                self.final_activation = 'sigmoid'\n            else:\n                self.final_activation = 'softmax'\n\n        if self.loss == None:\n            raise ValueError(f\"loss cannot be {self.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:51.748052Z","iopub.execute_input":"2024-08-15T20:01:51.748457Z","iopub.status.idle":"2024-08-15T20:01:51.812940Z","shell.execute_reply.started":"2024-08-15T20:01:51.748425Z","shell.execute_reply":"2024-08-15T20:01:51.811251Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\nvocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:51.815143Z","iopub.execute_input":"2024-08-15T20:01:51.816138Z","iopub.status.idle":"2024-08-15T20:01:53.070342Z","shell.execute_reply.started":"2024-08-15T20:01:51.816085Z","shell.execute_reply":"2024-08-15T20:01:53.069022Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d0bfc39ef044d68e76ea4863a9c3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ce0cae88ec4368a9aa29f564bd2e5c"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def selective_scan(u, delta, A, B, C, D):\n    # first step of A_bar = exp(ΔA), i.e., ΔA\n    dA = tf.einsum('bld,dn->bldn', delta, A) \n    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n    \n    dA_cumsum = tf.pad(\n        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n    \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n    \n    # Cumulative sum along all the input tokens, parallel prefix sum, \n    # calculates dA for all the input tokens parallely\n    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)  \n\n    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n    dA_cumsum = tf.exp(dA_cumsum)  \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n\n    x = dB_u * dA_cumsum\n    # 1e-12 to avoid division by 0\n    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12) \n\n    y = tf.einsum('bldn,bln->bld', x, C)\n    \n    return y + u * D ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:53.072312Z","iopub.execute_input":"2024-08-15T20:01:53.072718Z","iopub.status.idle":"2024-08-15T20:01:53.085621Z","shell.execute_reply.started":"2024-08-15T20:01:53.072685Z","shell.execute_reply":"2024-08-15T20:01:53.084089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MambaBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        args = modelargs\n        self.layer_id = modelargs.layer_id\n\n        self.in_projection = layers.Dense(\n            args.model_internal_dim * 2, \n            input_shape=(args.model_input_dims,), use_bias=False)\n\n        self.conv1d = layers.Conv1D(\n            filters=args.model_internal_dim,\n            use_bias=args.conv_use_bias,\n            kernel_size=args.conv_kernel_size,\n            groups=args.model_internal_dim,\n            data_format='channels_first',\n            padding='causal'\n        )\n\n        # this layer takes in current token 'x' \n        # and outputs the input-specific Δ, B, C (according to S6)\n        self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n\n        # this layer projects Δ from delta_t_rank to the mamba internal \n        # dimension\n        self.delta_t_projection = layers.Dense(args.model_internal_dim, \n                                               input_shape=(args.delta_t_rank,), use_bias=True)\n\n        self.A = repeat(\n                tf.range(1, args.model_states+1, dtype=tf.float32), \n                'n -> d n', d=args.model_internal_dim)\n\n        self.A_log = tf.Variable(\n                tf.math.log(self.A), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_A_log_{args.layer_id}\")\n\n        self.D = tf.Variable(\n                np.ones(args.model_internal_dim), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_D_{args.layer_id}\")\n\n        self.out_projection = layers.Dense(\n                args.model_input_dims, \n                input_shape=(args.model_internal_dim,), \n                use_bias=args.dense_use_bias)\n\n    def call(self, x):\n        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n        Official Implementation:\n            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n\n        (batch_size, seq_len, dimension) = x.shape\n\n        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n        (x, res) = tf.split(x_and_res, \n                            [self.args.model_internal_dim, \n                             self.args.model_internal_dim], axis=-1)\n        \n        x = rearrange(x, 'b l d_in -> b d_in l')\n        x = self.conv1d(x)[:, :, :seq_len]\n        x = rearrange(x, 'b d_in l -> b l d_in')\n        \n        x = tf.nn.swish(x)\n        y = self.ssm(x)\n        y = y * tf.nn.swish(res)\n        return self.out_projection(y)\n    \n    def ssm(self, x):\n        \"\"\"Runs the SSM. See:\n            - Algorithm 2 in Section 3.2 in the Mamba paper\n            - run_SSM(A, B, C, u) in The Annotated S4\n            Official Implementation:\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n        (d_in, n) = self.A_log.shape\n\n        # Compute ∆ A B C D, the state space parameters.\n        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n        #                                  and is why Mamba is called **selective** state spaces)\n\n        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n        D = tf.cast(self.D, tf.float32)\n\n        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n\n        (delta, B, C) = tf.split(\n                x_dbl, \n                num_or_size_splits=[self.args.delta_t_rank, n, n], \n                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n\n        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n\n        return selective_scan(x, delta, A, B, C, D)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:53.087698Z","iopub.execute_input":"2024-08-15T20:01:53.088188Z","iopub.status.idle":"2024-08-15T20:01:53.119420Z","shell.execute_reply.started":"2024-08-15T20:01:53.088153Z","shell.execute_reply":"2024-08-15T20:01:53.117078Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        self.mixer = MambaBlock(modelargs)\n        self.norm = layers.LayerNormalization(epsilon=1e-5)\n\n    def call(self, x):\n        \"\"\"\n        Official Implementation:\n            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n            \n            Note: the official repo chains residual blocks that look like\n                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n            where the first Add is a no-op. This is purely for performance reasons as this\n            allows them to fuse the Add->Norm.\n\n            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n            \n        \"\"\"\n        return self.mixer(self.norm(x)) + x","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:53.121474Z","iopub.execute_input":"2024-08-15T20:01:53.122024Z","iopub.status.idle":"2024-08-15T20:01:53.142864Z","shell.execute_reply.started":"2024-08-15T20:01:53.121958Z","shell.execute_reply":"2024-08-15T20:01:53.141080Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def init_model(args: ModelArgs):\n    input_layer = layers.Input(shape=(args.seq_length,), name='input_ids')\n    x = layers.Embedding(args.vocab_size, args.model_input_dims, input_length=args.seq_length)(input_layer)\n\n    for i in range(args.num_layers):\n        x = ResidualBlock(args, name=f\"Residual_{i}\")(x)\n        x = layers.Dropout(args.dropout_rate)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n    if not args.use_lm_head: # use flatten only if we are using the model as an LM\n        x = layers.Flatten()(x)\n    x = layers.Dense(1024, activation=tf.nn.gelu)(x)\n    output_layer = layers.Dense(args.num_classes, activation=args.final_activation)(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='MambaTimeModel')\n    model.compile(\n        loss=args.loss,\n        optimizer=args.optimizer,\n        metrics=args.metrics\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:53.145258Z","iopub.execute_input":"2024-08-15T20:01:53.145799Z","iopub.status.idle":"2024-08-15T20:01:53.164927Z","shell.execute_reply.started":"2024-08-15T20:01:53.145724Z","shell.execute_reply":"2024-08-15T20:01:53.162922Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"args = ModelArgs(\n    model_input_dims=max_seq_length,\n    model_states=32,\n    num_layers=12,\n    dropout_rate=0.2,\n    vocab_size=vocab_size,\n    num_classes=vocab_size\n)\nmodel = init_model(args)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:01:53.171699Z","iopub.execute_input":"2024-08-15T20:01:53.172196Z","iopub.status.idle":"2024-08-15T20:02:01.167517Z","shell.execute_reply.started":"2024-08-15T20:01:53.172163Z","shell.execute_reply":"2024-08-15T20:02:01.166059Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"MambaTimeModel\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MambaTimeModel\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m25,730,048\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_0 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_3 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_4 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_5 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_6 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_7 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_8 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_9 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_10 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_11 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,711,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │   \u001b[38;5;34m268,436,480\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,730,048</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,711,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">268,436,480</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m314,701,825\u001b[0m (1.17 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,701,825</span> (1.17 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m314,701,825\u001b[0m (1.17 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,701,825</span> (1.17 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom tqdm import tqdm\n\ndataset = load_dataset(\"neuralwork/fashion-style-instruct\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:16.181025Z","iopub.execute_input":"2024-08-15T20:03:16.181450Z","iopub.status.idle":"2024-08-15T20:03:17.241255Z","shell.execute_reply.started":"2024-08-15T20:03:16.181416Z","shell.execute_reply":"2024-08-15T20:03:17.239832Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:17.243411Z","iopub.execute_input":"2024-08-15T20:03:17.243823Z","iopub.status.idle":"2024-08-15T20:03:17.253262Z","shell.execute_reply.started":"2024-08-15T20:03:17.243790Z","shell.execute_reply":"2024-08-15T20:03:17.251056Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'completion', 'context'],\n    num_rows: 3193\n})"},"metadata":{}}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token \nEOS_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:17.255322Z","iopub.execute_input":"2024-08-15T20:03:17.255713Z","iopub.status.idle":"2024-08-15T20:03:17.278403Z","shell.execute_reply.started":"2024-08-15T20:03:17.255682Z","shell.execute_reply":"2024-08-15T20:03:17.276877Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}]},{"cell_type":"code","source":"inputFormatString = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Context:\n{}\n\n### Input:\n{}\"\"\"\n\noutputFormatString = \"\"\"### Completion:\n{}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:17.280892Z","iopub.execute_input":"2024-08-15T20:03:17.282724Z","iopub.status.idle":"2024-08-15T20:03:17.297798Z","shell.execute_reply.started":"2024-08-15T20:03:17.282675Z","shell.execute_reply":"2024-08-15T20:03:17.296440Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Define the function to create the new 'text' column\ndef formatDatasetAlpaca(sample):\n    context = sample['context']\n    inputText = sample['input']\n    completion = sample['completion']\n    \n    sampleInput = inputFormatString.format(context, inputText) + EOS_TOKEN\n    sampleOutput = outputFormatString.format(completion) + EOS_TOKEN\n    \n    sample['inputText'] = sampleInput\n    sample['outputText'] = sampleOutput\n    \n    return sample\n\n# Apply the function to the dataset\ndataset = dataset.map(formatDatasetAlpaca, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:17.385703Z","iopub.execute_input":"2024-08-15T20:03:17.386487Z","iopub.status.idle":"2024-08-15T20:03:17.831794Z","shell.execute_reply.started":"2024-08-15T20:03:17.386445Z","shell.execute_reply":"2024-08-15T20:03:17.830430Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3193 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbed933e143d40f9b04f9cc38d141cc4"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.3)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:17.834172Z","iopub.execute_input":"2024-08-15T20:03:17.834658Z","iopub.status.idle":"2024-08-15T20:03:17.859050Z","shell.execute_reply.started":"2024-08-15T20:03:17.834618Z","shell.execute_reply":"2024-08-15T20:03:17.857479Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 2235\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 958\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"pprint.pprint(dataset['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:18.220803Z","iopub.execute_input":"2024-08-15T20:03:18.221365Z","iopub.status.idle":"2024-08-15T20:03:18.230661Z","shell.execute_reply.started":"2024-08-15T20:03:18.221325Z","shell.execute_reply":"2024-08-15T20:03:18.229050Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"{'inputText': 'Below is an instruction that describes a task, paired with an '\n              'input that provides further context. Write a response that '\n              'appropriately completes the request.\\n'\n              '\\n'\n              '### Context:\\n'\n              \"I'm going to a casual gathering.\\n\"\n              '\\n'\n              '### Input:\\n'\n              \"I'm a middle-aged man with a compact, sturdy build. I like \"\n              \"smart-casual clothing that's comfortable yet put-together, like \"\n              'crewneck sweaters and khakis.<|endoftext|>',\n 'outputText': '### Completion:\\n'\n               'Outfit 1:\\n'\n               '- Top: A crewneck sweater in a neutral color like navy or '\n               'charcoal gray.\\n'\n               '- Bottom: Slim-fitting khaki pants.\\n'\n               '- Shoe: Brown leather loafers to add a touch of '\n               'sophistication.\\n'\n               '- Accessories: A brown leather belt and a classic wristwatch.\\n'\n               '\\n'\n               'Outfit 2:\\n'\n               '- Top: A plaid button-down shirt in earth tones.\\n'\n               '- Bottom: Dark wash denim jeans.\\n'\n               '- Shoe: Brown suede Chelsea boots for a trendy yet laid-back '\n               'look.\\n'\n               '- Accessories: A leather bracelet and a beanie hat for a cool '\n               'touch.\\n'\n               '\\n'\n               'Outfit 3:\\n'\n               '- Top: A light blue oxford shirt.\\n'\n               '- Bottom: Slim-fit chinos in a light beige or stone color.\\n'\n               '- Shoe: Tan suede desert boots for a relaxed yet polished '\n               'vibe.\\n'\n               '- Accessories: A patterned silk pocket square and a leather '\n               'messenger bag.\\n'\n               '\\n'\n               'Outfit 4:\\n'\n               '- Top: A lightweight gray or navy linen-blend polo shirt.\\n'\n               '- Bottom: Tailored navy shorts above the knee.\\n'\n               '- Shoe: White sneakers for a sporty and fresh appearance.\\n'\n               '- Accessories: A straw fedora hat and some fashionable '\n               'sunglasses.\\n'\n               '\\n'\n               'Outfit 5:\\n'\n               '- Top: A classic white button-down shirt.\\n'\n               '- Bottom: Charcoal gray trousers in a slim-fit style.\\n'\n               '- Shoe: Brown leather brogues for a timeless touch.\\n'\n               '- Accessories: A silk tie in a subtle pattern and a leather '\n               'briefcase.\\n'\n               '<|endoftext|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:03:41.171479Z","iopub.execute_input":"2024-08-15T20:03:41.171904Z","iopub.status.idle":"2024-08-15T20:03:41.180055Z","shell.execute_reply.started":"2024-08-15T20:03:41.171873Z","shell.execute_reply":"2024-08-15T20:03:41.178675Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 2235\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 958\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_texts = dataset['train']['inputText']\ntrain_completions = dataset['train']['outputText']\n\ntest_texts = dataset['test']['inputText']\ntest_completions = dataset['test']['outputText']","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:07:07.993196Z","iopub.execute_input":"2024-08-15T20:07:07.993700Z","iopub.status.idle":"2024-08-15T20:07:08.072632Z","shell.execute_reply.started":"2024-08-15T20:07:07.993666Z","shell.execute_reply":"2024-08-15T20:07:08.071530Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=200)\ntrain_labels = tokenizer(train_completions, truncation=True, padding=True, max_length=200)\n\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=200)\ntest_labels = tokenizer(test_completions, truncation=True, padding=True, max_length=200)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:13:38.681411Z","iopub.execute_input":"2024-08-15T20:13:38.682884Z","iopub.status.idle":"2024-08-15T20:13:41.499175Z","shell.execute_reply.started":"2024-08-15T20:13:38.682831Z","shell.execute_reply":"2024-08-15T20:13:41.498035Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_labels.keys()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:09:10.963145Z","iopub.execute_input":"2024-08-15T20:09:10.964468Z","iopub.status.idle":"2024-08-15T20:09:10.971428Z","shell.execute_reply.started":"2024-08-15T20:09:10.964429Z","shell.execute_reply":"2024-08-15T20:09:10.970224Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to TensorFlow Datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),  # input_ids and attention_mask\n    train_labels['input_ids']  # labels (target sequences)\n))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),  # input_ids and attention_mask\n    test_labels['input_ids']  # labels (target sequences)\n))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:09:32.284912Z","iopub.execute_input":"2024-08-15T20:09:32.285338Z","iopub.status.idle":"2024-08-15T20:09:36.153347Z","shell.execute_reply.started":"2024-08-15T20:09:32.285307Z","shell.execute_reply":"2024-08-15T20:09:36.152122Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Batch and shuffle the datasets\nBATCH_SIZE = 32\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:10:34.685766Z","iopub.execute_input":"2024-08-15T20:10:34.687596Z","iopub.status.idle":"2024-08-15T20:10:34.701770Z","shell.execute_reply.started":"2024-08-15T20:10:34.687530Z","shell.execute_reply":"2024-08-15T20:10:34.700473Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# list(train_dataset.as_numpy_iterator())","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:12:14.065083Z","iopub.execute_input":"2024-08-15T20:12:14.066734Z","iopub.status.idle":"2024-08-15T20:12:14.071820Z","shell.execute_reply.started":"2024-08-15T20:12:14.066677Z","shell.execute_reply":"2024-08-15T20:12:14.070219Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, epochs=1, validation_data=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:02:06.949160Z","iopub.status.idle":"2024-08-15T20:02:06.949616Z","shell.execute_reply.started":"2024-08-15T20:02:06.949400Z","shell.execute_reply":"2024-08-15T20:02:06.949424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}