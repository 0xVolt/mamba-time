{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n# %pip install tensorflow[and-cuda]==2.15.0.post1 transformers==4.36.2 einops==0.7.0 datasets==2.16.1\n%pip install -qU transformers==4.36.2 einops==0.7.0 datasets==2.16.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T12:21:47.374968Z","iopub.execute_input":"2024-08-21T12:21:47.375918Z","iopub.status.idle":"2024-08-21T12:22:15.135905Z","shell.execute_reply.started":"2024-08-21T12:21:47.375883Z","shell.execute_reply":"2024-08-21T12:22:15.134753Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ngcsfs 2024.5.0 requires fsspec==2024.5.0, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ns3fs 2024.5.0 requires fsspec==2024.5.0.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCPU times: user 373 ms, sys: 73 ms, total: 446 ms\nWall time: 27.7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\n\nfrom dataclasses import dataclass\nfrom einops import rearrange, repeat\nfrom typing import Union\n\nfrom transformers import AutoTokenizer\n\nimport datasets\nimport math\nimport numpy as np\nimport pprint","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:15.138310Z","iopub.execute_input":"2024-08-21T12:22:15.138657Z","iopub.status.idle":"2024-08-21T12:22:33.119335Z","shell.execute_reply.started":"2024-08-21T12:22:15.138627Z","shell.execute_reply":"2024-08-21T12:22:33.118590Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-21 12:22:18.700277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-21 12:22:18.700382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-21 12:22:18.839876: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# session = tf.Session()\n\n# with session.as_default():\n#     print(tensor.eval())","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.120473Z","iopub.execute_input":"2024-08-21T12:22:33.121175Z","iopub.status.idle":"2024-08-21T12:22:33.125198Z","shell.execute_reply.started":"2024-08-21T12:22:33.121136Z","shell.execute_reply":"2024-08-21T12:22:33.124335Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 128","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.127885Z","iopub.execute_input":"2024-08-21T12:22:33.128285Z","iopub.status.idle":"2024-08-21T12:22:33.140613Z","shell.execute_reply.started":"2024-08-21T12:22:33.128256Z","shell.execute_reply":"2024-08-21T12:22:33.139772Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n\n# # tf.compat.v1.enable_eager_execution()\n# tf.compat.v1.disable_eager_execution()\n\n# def customBLEU(y_true, y_pred):\n#     # Assuming y_true and y_pred are tokenized sequences, convert them to numpy arrays\n#     y_true = y_true.eval(session=tf.compat.v1.Session())\n#     y_pred = y_pred.eval(session=tf.compat.v1.Session())\n    \n#     bleu_scores = []\n#     for true_seq, pred_seq in zip(y_true, y_pred):\n#         # Convert tensors to numpy arrays\n#         # true_seq = true_seq.numpy()\n#         # pred_seq = pred_seq.numpy()\n        \n#         bleu_scores.append(sentence_bleu([true_seq], pred_seq))\n\n#     # Convert BLEU scores to a TensorFlow tensor for compatibility\n#     bleu_scores = tf.constant(bleu_scores)\n#     return tf.reduce_mean(bleu_scores)\n\n# # Create test case\n# y_true = tf.convert_to_tensor([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=tf.int32)\n# y_pred = tf.convert_to_tensor([[1, 2, 3, 4], [5, 6, 0, 8]], dtype=tf.int32)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.141724Z","iopub.execute_input":"2024-08-21T12:22:33.142129Z","iopub.status.idle":"2024-08-21T12:22:33.150613Z","shell.execute_reply.started":"2024-08-21T12:22:33.142100Z","shell.execute_reply":"2024-08-21T12:22:33.149641Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# print(customBLEU(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.151889Z","iopub.execute_input":"2024-08-21T12:22:33.152127Z","iopub.status.idle":"2024-08-21T12:22:33.160136Z","shell.execute_reply.started":"2024-08-21T12:22:33.152107Z","shell.execute_reply":"2024-08-21T12:22:33.159270Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ModelArgs:\n    model_input_dims: int = 64\n    model_states: int = 64\n    projection_expand_factor: int = 2\n    conv_kernel_size: int = 4\n    delta_t_min: float = 0.001\n    delta_t_max: float = 0.1\n    delta_t_scale: float = 0.1\n    delta_t_init_floor: float = 1e-4\n    conv_use_bias: bool = True\n    dense_use_bias: bool = False\n    layer_id: int = -1\n    seq_length: int = max_seq_length\n    num_layers: int = 5\n    dropout_rate: float = 0.2\n    use_lm_head: float = True\n    num_classes: int = None\n    vocab_size: int = None\n    final_activation = None\n    # loss: Union[str, keras.losses.Loss] = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    optimizer: Union[str, keras.optimizers.Optimizer] = keras.optimizers.AdamW(clipnorm=1.0, learning_rate=1e-5)\n    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n    jit_compile=True\n\n    def __post_init__(self):\n        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n\n        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n        if self.layer_id == -1:\n            self.layer_id = np.round(np.random.randint(0, 1000), 4)\n\n        if self.vocab_size == None:\n            raise ValueError(\"vocab size cannot be none\")\n\n        if self.use_lm_head:\n            self.num_classes=self.vocab_size\n        else:\n            if self.num_classes == None:\n                raise ValueError(f'num classes cannot be {self.num_classes}')\n\n            if self.num_classes == 1:\n                self.final_activation = 'sigmoid'\n            else:\n                self.final_activation = 'softmax'\n\n        if self.loss == None:\n            raise ValueError(f\"loss cannot be {self.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.161270Z","iopub.execute_input":"2024-08-21T12:22:33.161572Z","iopub.status.idle":"2024-08-21T12:22:33.859534Z","shell.execute_reply.started":"2024-08-21T12:22:33.161549Z","shell.execute_reply":"2024-08-21T12:22:33.858590Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\nvocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:33.860704Z","iopub.execute_input":"2024-08-21T12:22:33.861005Z","iopub.status.idle":"2024-08-21T12:22:35.073011Z","shell.execute_reply.started":"2024-08-21T12:22:33.860981Z","shell.execute_reply":"2024-08-21T12:22:35.072068Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44552cb4afc74164b2d26de02d528ef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc8514a64074381804a8a5633fb346a"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def selective_scan(u, delta, A, B, C, D):\n    # first step of A_bar = exp(ΔA), i.e., ΔA\n    dA = tf.einsum('bld,dn->bldn', delta, A) \n    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n    \n    dA_cumsum = tf.pad(\n        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n    \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n    \n    # Cumulative sum along all the input tokens, parallel prefix sum, \n    # calculates dA for all the input tokens parallely\n    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)  \n\n    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n    dA_cumsum = tf.exp(dA_cumsum)  \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n\n    x = dB_u * dA_cumsum\n    # 1e-12 to avoid division by 0\n    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12) \n\n    y = tf.einsum('bldn,bln->bld', x, C)\n    \n    return y + u * D ","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:35.074375Z","iopub.execute_input":"2024-08-21T12:22:35.074776Z","iopub.status.idle":"2024-08-21T12:22:35.083619Z","shell.execute_reply.started":"2024-08-21T12:22:35.074742Z","shell.execute_reply":"2024-08-21T12:22:35.082635Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class MambaBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        args = modelargs\n        self.layer_id = modelargs.layer_id\n\n        self.in_projection = layers.Dense(\n            args.model_internal_dim * 2, \n            input_shape=(args.model_input_dims,), use_bias=False)\n\n        self.conv1d = layers.Conv1D(\n            filters=args.model_internal_dim,\n            use_bias=args.conv_use_bias,\n            kernel_size=args.conv_kernel_size,\n            groups=args.model_internal_dim,\n            data_format='channels_first',\n            padding='causal'\n        )\n\n        # this layer takes in current token 'x' \n        # and outputs the input-specific Δ, B, C (according to S6)\n        self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n\n        # this layer projects Δ from delta_t_rank to the mamba internal \n        # dimension\n        self.delta_t_projection = layers.Dense(args.model_internal_dim, \n                                               input_shape=(args.delta_t_rank,), use_bias=True)\n\n        self.A = repeat(\n                tf.range(1, args.model_states+1, dtype=tf.float32), \n                'n -> d n', d=args.model_internal_dim)\n\n        self.A_log = tf.Variable(\n                tf.math.log(self.A), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_A_log_{args.layer_id}\")\n\n        self.D = tf.Variable(\n                np.ones(args.model_internal_dim), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_D_{args.layer_id}\")\n\n        self.out_projection = layers.Dense(\n                args.model_input_dims, \n                input_shape=(args.model_internal_dim,), \n                use_bias=args.dense_use_bias)\n\n    def call(self, x):\n        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n        Official Implementation:\n            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n\n        (batch_size, seq_len, dimension) = x.shape\n\n        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n        (x, res) = tf.split(x_and_res, \n                            [self.args.model_internal_dim, \n                             self.args.model_internal_dim], axis=-1)\n        \n        x = rearrange(x, 'b l d_in -> b d_in l')\n        x = self.conv1d(x)[:, :, :seq_len]\n        x = rearrange(x, 'b d_in l -> b l d_in')\n        \n        x = tf.nn.swish(x)\n        y = self.ssm(x)\n        y = y * tf.nn.swish(res)\n        return self.out_projection(y)\n    \n    def ssm(self, x):\n        \"\"\"Runs the SSM. See:\n            - Algorithm 2 in Section 3.2 in the Mamba paper\n            - run_SSM(A, B, C, u) in The Annotated S4\n            Official Implementation:\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n        (d_in, n) = self.A_log.shape\n\n        # Compute ∆ A B C D, the state space parameters.\n        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n        #                                  and is why Mamba is called **selective** state spaces)\n\n        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n        D = tf.cast(self.D, tf.float32)\n\n        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n\n        (delta, B, C) = tf.split(\n                x_dbl, \n                num_or_size_splits=[self.args.delta_t_rank, n, n], \n                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n\n        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n\n        return selective_scan(x, delta, A, B, C, D)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:35.087357Z","iopub.execute_input":"2024-08-21T12:22:35.087646Z","iopub.status.idle":"2024-08-21T12:22:35.132386Z","shell.execute_reply.started":"2024-08-21T12:22:35.087623Z","shell.execute_reply":"2024-08-21T12:22:35.131489Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        self.mixer = MambaBlock(modelargs)\n        self.norm = layers.LayerNormalization(epsilon=1e-5)\n\n    def call(self, x):\n        \"\"\"\n        Official Implementation:\n            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n            \n            Note: the official repo chains residual blocks that look like\n                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n            where the first Add is a no-op. This is purely for performance reasons as this\n            allows them to fuse the Add->Norm.\n\n            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n            \n        \"\"\"\n        return self.mixer(self.norm(x)) + x","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:35.133689Z","iopub.execute_input":"2024-08-21T12:22:35.134061Z","iopub.status.idle":"2024-08-21T12:22:35.145712Z","shell.execute_reply.started":"2024-08-21T12:22:35.134028Z","shell.execute_reply":"2024-08-21T12:22:35.144852Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def init_model(args: ModelArgs):\n    input_layer = layers.Input(shape=(args.seq_length,), name='input_ids')\n    x = layers.Embedding(args.vocab_size, args.model_input_dims, input_length=args.seq_length)(input_layer)\n\n    for i in range(args.num_layers):\n        x = ResidualBlock(args, name=f\"Residual_{i}\")(x)\n        x = layers.Dropout(args.dropout_rate)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n    if not args.use_lm_head: # use flatten only if we are using the model as an LM\n        x = layers.Flatten()(x)\n    x = layers.Dense(1024, activation=tf.nn.gelu)(x)\n    output_layer = layers.Dense(args.num_classes, activation=args.final_activation)(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='MambaTimeModel')\n    model.compile(\n        loss=args.loss,\n        optimizer=args.optimizer,\n        metrics=args.metrics\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:35.146812Z","iopub.execute_input":"2024-08-21T12:22:35.147127Z","iopub.status.idle":"2024-08-21T12:22:35.159151Z","shell.execute_reply.started":"2024-08-21T12:22:35.147098Z","shell.execute_reply":"2024-08-21T12:22:35.158279Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"args = ModelArgs(\n    model_input_dims=max_seq_length,\n    model_states=32,\n    num_layers=12,\n    dropout_rate=0.2,\n    vocab_size=vocab_size\n)\nmodel = init_model(args)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:35.160246Z","iopub.execute_input":"2024-08-21T12:22:35.160620Z","iopub.status.idle":"2024-08-21T12:22:39.489921Z","shell.execute_reply.started":"2024-08-21T12:22:35.160590Z","shell.execute_reply":"2024-08-21T12:22:39.489104Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"MambaTimeModel\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MambaTimeModel\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,432,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_0 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_3 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_4 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_5 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_6 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_7 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_8 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_9 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_10 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_11 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m120,576\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │       \u001b[38;5;34m132,096\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m50254\u001b[0m)     │    \u001b[38;5;34m51,510,350\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Residual_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,576</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,096</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50254</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">51,510,350</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,522,126\u001b[0m (227.06 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,522,126</span> (227.06 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m59,522,126\u001b[0m (227.06 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,522,126</span> (227.06 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom tqdm import tqdm\n\ndataset = load_dataset(\"neuralwork/fashion-style-instruct\", split=\"train[:1000]\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:39.490938Z","iopub.execute_input":"2024-08-21T12:22:39.491182Z","iopub.status.idle":"2024-08-21T12:22:42.666714Z","shell.execute_reply.started":"2024-08-21T12:22:39.491160Z","shell.execute_reply":"2024-08-21T12:22:42.665982Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/882 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90baf477b3f842fab173c5c185c28b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.64M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7136c7c84524446ab90c3e55c0b22733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3193 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf93fe173c44da499bd7b0649fbf559"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.667861Z","iopub.execute_input":"2024-08-21T12:22:42.668141Z","iopub.status.idle":"2024-08-21T12:22:42.673622Z","shell.execute_reply.started":"2024-08-21T12:22:42.668117Z","shell.execute_reply":"2024-08-21T12:22:42.672831Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'completion', 'context'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token \nEOS_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.674841Z","iopub.execute_input":"2024-08-21T12:22:42.675107Z","iopub.status.idle":"2024-08-21T12:22:42.686743Z","shell.execute_reply.started":"2024-08-21T12:22:42.675083Z","shell.execute_reply":"2024-08-21T12:22:42.685936Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}]},{"cell_type":"code","source":"inputFormatString = \"\"\"You are a personal stylist recommending fashion advice and clothing combinations. Use the self body and style description below, combined with the event described in the context to generate 5 self-contained and complete outfit combinations.\n### Context:\n{}\n\n### Input:\n{}\"\"\"\n\noutputFormatString = \"\"\"### Completion:\n{}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.688022Z","iopub.execute_input":"2024-08-21T12:22:42.688305Z","iopub.status.idle":"2024-08-21T12:22:42.695237Z","shell.execute_reply.started":"2024-08-21T12:22:42.688281Z","shell.execute_reply":"2024-08-21T12:22:42.694444Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define the function to create the new 'text' column\ndef formatDatasetAlpaca(sample):\n    context = sample['context']\n    inputText = sample['input']\n    completion = sample['completion']\n    \n    sampleInput = inputFormatString.format(context, inputText) + EOS_TOKEN\n    sampleOutput = outputFormatString.format(completion) + EOS_TOKEN\n    \n    sample['inputText'] = sampleInput\n    sample['outputText'] = sampleOutput\n    \n    return sample\n\n# Apply the function to the dataset\ndataset = dataset.map(formatDatasetAlpaca, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.696203Z","iopub.execute_input":"2024-08-21T12:22:42.696493Z","iopub.status.idle":"2024-08-21T12:22:42.830297Z","shell.execute_reply.started":"2024-08-21T12:22:42.696460Z","shell.execute_reply":"2024-08-21T12:22:42.829452Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e43e939863646cba116bb94926de3a4"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.3)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.831341Z","iopub.execute_input":"2024-08-21T12:22:42.831869Z","iopub.status.idle":"2024-08-21T12:22:42.845328Z","shell.execute_reply.started":"2024-08-21T12:22:42.831843Z","shell.execute_reply":"2024-08-21T12:22:42.844479Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 700\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 300\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"pprint.pprint(dataset['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.846393Z","iopub.execute_input":"2024-08-21T12:22:42.846968Z","iopub.status.idle":"2024-08-21T12:22:42.859682Z","shell.execute_reply.started":"2024-08-21T12:22:42.846944Z","shell.execute_reply":"2024-08-21T12:22:42.858789Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'inputText': 'You are a personal stylist recommending fashion advice and '\n              'clothing combinations. Use the self body and style description '\n              'below, combined with the event described in the context to '\n              'generate 5 self-contained and complete outfit combinations.\\n'\n              '### Context:\\n'\n              'I usually go for jeans and tees with an edgy, androgynous look '\n              \"I'm going to a play / concert.\\n\"\n              '\\n'\n              '### Input:\\n'\n              \"I'm a tomboyish woman with big biceps and shoulders from \"\n              'weightlifting.<|endoftext|>',\n 'outputText': '### Completion:\\n'\n               'Outfit Combination 1:\\n'\n               '- Top: A fitted leather jacket with shoulder pads to enhance '\n               'your shoulders and give structure to the look.\\n'\n               '- Bottom: Black ripped skinny jeans for a edgy and rugged '\n               'touch.\\n'\n               '- Shoe: Black combat boots for a comfortable yet stylish '\n               'option.\\n'\n               '- Accessories: Chunky silver hoop earrings and a black studded '\n               'belt to complete the edgy look.\\n'\n               '\\n'\n               'Outfit Combination 2:\\n'\n               '- Top: A graphic band tee,\\n'\n               '- Bottom: High-waisted distressed denim shorts for a casual '\n               'and playful vibe.\\n'\n               '- Shoe: White sneakers for a cool and relaxed look.\\n'\n               '- Accessories: Layered silver necklaces and a black leather '\n               'backpack for a touch of accessorizing.\\n'\n               '\\n'\n               'Outfit Combination 3:\\n'\n               '- Top: A black oversized blazer, preferably with bold shoulder '\n               'pads, to make a statement.\\n'\n               '- Bottom: Fitted black leather pants for a sleek and polished '\n               'appearance.\\n'\n               '- Shoe: Pointed-toe heeled ankle boots in patent leather for '\n               'added glam.\\n'\n               '- Accessories: A silver choker and a structured black handbag '\n               'to complete the look.\\n'\n               '\\n'\n               'Outfit Combination 4:\\n'\n               '- Top: A white button-down shirt styled in a half-tuck for a '\n               'laid-back but chic vibe.\\n'\n               '- Bottom: Dark wash boyfriend jeans for a comfortable and '\n               'stylish look.\\n'\n               '- Shoe: White low-top sneakers for a classic and casual '\n               'touch.\\n'\n               '- Accessories: A black leather watch and a black fedora hat '\n               'for a touch of masculinity.\\n'\n               '\\n'\n               'Outfit Combination 5:\\n'\n               '- Top: A sleeveless muscle tank with a bold graphic print to '\n               'show off your biceps.\\n'\n               '- Bottom: High-waisted black joggers for a comfortable and '\n               'sporty look.\\n'\n               '- Shoe: White high-top sneakers for a cool and athletic vibe.\\n'\n               '- Accessories: Stackable bracelets and a sporty backpack for a '\n               'stylish and functional touch.\\n'\n               '<|endoftext|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.860831Z","iopub.execute_input":"2024-08-21T12:22:42.861064Z","iopub.status.idle":"2024-08-21T12:22:42.870954Z","shell.execute_reply.started":"2024-08-21T12:22:42.861044Z","shell.execute_reply":"2024-08-21T12:22:42.870008Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 700\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 300\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_texts = dataset['train']['inputText']\ntrain_completions = dataset['train']['outputText']\n\ntest_texts = dataset['test']['inputText']\ntest_completions = dataset['test']['outputText']","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.872214Z","iopub.execute_input":"2024-08-21T12:22:42.872531Z","iopub.status.idle":"2024-08-21T12:22:42.898045Z","shell.execute_reply.started":"2024-08-21T12:22:42.872502Z","shell.execute_reply":"2024-08-21T12:22:42.897220Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"np.shape(train_texts)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.899099Z","iopub.execute_input":"2024-08-21T12:22:42.899339Z","iopub.status.idle":"2024-08-21T12:22:42.905323Z","shell.execute_reply.started":"2024-08-21T12:22:42.899318Z","shell.execute_reply":"2024-08-21T12:22:42.904584Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(700,)"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding='max_length', max_length=max_seq_length)\ntrain_labels = tokenizer(train_completions, truncation=True, padding='max_length', max_length=max_seq_length)\n\ntest_encodings = tokenizer(test_texts, truncation=True, padding='max_length', max_length=max_seq_length)\ntest_labels = tokenizer(test_completions, truncation=True, padding='max_length', max_length=max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:42.906480Z","iopub.execute_input":"2024-08-21T12:22:42.906736Z","iopub.status.idle":"2024-08-21T12:22:43.638050Z","shell.execute_reply.started":"2024-08-21T12:22:42.906714Z","shell.execute_reply":"2024-08-21T12:22:43.637215Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"np.shape(train_encodings['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:43.639103Z","iopub.execute_input":"2024-08-21T12:22:43.639395Z","iopub.status.idle":"2024-08-21T12:22:43.653823Z","shell.execute_reply.started":"2024-08-21T12:22:43.639370Z","shell.execute_reply":"2024-08-21T12:22:43.652876Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(700, 128)"},"metadata":{}}]},{"cell_type":"code","source":"np.shape(train_labels['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:43.654848Z","iopub.execute_input":"2024-08-21T12:22:43.655118Z","iopub.status.idle":"2024-08-21T12:22:43.672009Z","shell.execute_reply.started":"2024-08-21T12:22:43.655087Z","shell.execute_reply":"2024-08-21T12:22:43.671139Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(700, 128)"},"metadata":{}}]},{"cell_type":"code","source":"train_labels.keys()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:43.673107Z","iopub.execute_input":"2024-08-21T12:22:43.673423Z","iopub.status.idle":"2024-08-21T12:22:43.681177Z","shell.execute_reply.started":"2024-08-21T12:22:43.673394Z","shell.execute_reply":"2024-08-21T12:22:43.680255Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to TensorFlow Datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),  # input_ids and attention_mask\n    train_labels['input_ids']  # labels (target sequences)\n))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),  # input_ids and attention_mask\n    test_labels['input_ids']  # labels (target sequences)\n))","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:43.685937Z","iopub.execute_input":"2024-08-21T12:22:43.686203Z","iopub.status.idle":"2024-08-21T12:22:44.841225Z","shell.execute_reply.started":"2024-08-21T12:22:43.686181Z","shell.execute_reply":"2024-08-21T12:22:44.840475Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Batch and shuffle the datasets\nBATCH_SIZE = 8\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:44.842320Z","iopub.execute_input":"2024-08-21T12:22:44.842612Z","iopub.status.idle":"2024-08-21T12:22:44.857826Z","shell.execute_reply.started":"2024-08-21T12:22:44.842588Z","shell.execute_reply":"2024-08-21T12:22:44.856341Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Print out the train dataset tensors; if you're insane\n# list(train_dataset.as_numpy_iterator())","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:44.858986Z","iopub.execute_input":"2024-08-21T12:22:44.859315Z","iopub.status.idle":"2024-08-21T12:22:44.866359Z","shell.execute_reply.started":"2024-08-21T12:22:44.859289Z","shell.execute_reply":"2024-08-21T12:22:44.865476Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = model.fit(train_dataset, validation_data=test_dataset, epochs=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T12:22:44.867387Z","iopub.execute_input":"2024-08-21T12:22:44.867716Z","iopub.status.idle":"2024-08-21T12:26:59.747188Z","shell.execute_reply.started":"2024-08-21T12:22:44.867692Z","shell.execute_reply":"2024-08-21T12:26:59.746267Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1724243035.375346     110 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1724243035.442302     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.443436     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.444101     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.444770     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.445449     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.446100     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.446790     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.447451     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.448081     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.448797     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.449507     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.450134     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243035.452146     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m10/88\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 510ms/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724243083.892447     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.893127     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.893747     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.894314     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.894874     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.895449     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.895992     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.896569     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.897098     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.897696     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.898251     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243083.899017     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00 - val_loss: nan - val_sparse_categorical_accuracy: 0.0000e+00\nEpoch 2/2\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724243137.666959     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.667472     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.668035     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.668563     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.668964     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.669377     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.669791     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.670185     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.670613     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.671003     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.671411     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1724243137.671894     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 603ms/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00 - val_loss: nan - val_sparse_categorical_accuracy: 0.0000e+00\nCPU times: user 4min 1s, sys: 2.52 s, total: 4min 4s\nWall time: 4min 14s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}