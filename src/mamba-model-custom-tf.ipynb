{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n# %pip install tensorflow[and-cuda]==2.15.0.post1 transformers==4.36.2 einops==0.7.0 datasets==2.16.1\n%pip install -qU transformers==4.36.2 einops==0.7.0 datasets==2.16.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-15T21:38:34.161188Z","iopub.execute_input":"2024-08-15T21:38:34.161524Z","iopub.status.idle":"2024-08-15T21:38:46.957221Z","shell.execute_reply.started":"2024-08-15T21:38:34.161495Z","shell.execute_reply":"2024-08-15T21:38:46.956154Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\nCPU times: user 141 ms, sys: 39.4 ms, total: 180 ms\nWall time: 12.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\n\nfrom dataclasses import dataclass\nfrom einops import rearrange, repeat\nfrom typing import Union\n\nfrom transformers import AutoTokenizer\n\nimport datasets\nimport math\nimport numpy as np\nimport pprint","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:46.959171Z","iopub.execute_input":"2024-08-15T21:38:46.959475Z","iopub.status.idle":"2024-08-15T21:38:54.075255Z","shell.execute_reply.started":"2024-08-15T21:38:46.959440Z","shell.execute_reply":"2024-08-15T21:38:54.074259Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-15 21:38:47.903941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 21:38:47.904011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 21:38:47.905512: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"max_seq_length = 128","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:54.076727Z","iopub.execute_input":"2024-08-15T21:38:54.077818Z","iopub.status.idle":"2024-08-15T21:38:54.082074Z","shell.execute_reply.started":"2024-08-15T21:38:54.077778Z","shell.execute_reply":"2024-08-15T21:38:54.081131Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n\ntf.compat.v1.enable_eager_execution()\n\ndef customBLEU(y_true, y_pred):\n    # Assuming y_true and y_pred are tokenized sequences\n    bleu_scores = []\n    for true_seq, pred_seq in zip(y_true, y_pred):\n        # Convert tensors to lists for NLTK compatibility\n        true_seq = true_seq.numpy().tolist()\n        pred_seq = pred_seq.numpy().tolist()\n        bleu_scores.append(sentence_bleu([true_seq], pred_seq))\n\n    # Convert BLEU scores to a TensorFlow tensor for compatibility\n    bleu_scores = tf.constant(bleu_scores)\n    return tf.reduce_mean(bleu_scores)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:54.084065Z","iopub.execute_input":"2024-08-15T21:38:54.084345Z","iopub.status.idle":"2024-08-15T21:38:54.652524Z","shell.execute_reply.started":"2024-08-15T21:38:54.084320Z","shell.execute_reply":"2024-08-15T21:38:54.651448Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ModelArgs:\n    model_input_dims: int = 64\n    model_states: int = 64\n    projection_expand_factor: int = 2\n    conv_kernel_size: int = 4\n    delta_t_min: float = 0.001\n    delta_t_max: float = 0.1\n    delta_t_scale: float = 0.1\n    delta_t_init_floor: float = 1e-4\n    conv_use_bias: bool = True\n    dense_use_bias: bool = False\n    layer_id: int = -1\n    seq_length: int = max_seq_length\n    num_layers: int = 5\n    dropout_rate: float = 0.2\n    use_lm_head: float = True\n    num_classes: int = None\n    vocab_size: int = None\n    final_activation = None\n    loss: Union[str, keras.losses.Loss] = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n#     loss: Union[str, keras.losses.Loss] = 'sparse_categorical_crossentropy'\n    optimizer: Union[str, keras.optimizers.Optimizer] = keras.optimizers.AdamW(clipnorm=1.0, learning_rate=1e-4)\n    metrics = [\n        customBLEU\n        # BLEUMetric(),\n        # tf.keras.metrics.SparseCategoricalAccuracy(name='token_accuracy'),\n    ]\n\n    def __post_init__(self):\n        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n\n        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n        if self.layer_id == -1:\n            self.layer_id = np.round(np.random.randint(0, 1000), 4)\n\n        if self.vocab_size == None:\n            raise ValueError(\"vocab size cannot be none\")\n\n        if self.use_lm_head:\n            self.num_classes=self.vocab_size\n        else:\n            if self.num_classes == None:\n                raise ValueError(f'num classes cannot be {self.num_classes}')\n\n            if self.num_classes == 1:\n                self.final_activation = 'sigmoid'\n            else:\n                self.final_activation = 'softmax'\n\n        if self.loss == None:\n            raise ValueError(f\"loss cannot be {self.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:54.653961Z","iopub.execute_input":"2024-08-15T21:38:54.654368Z","iopub.status.idle":"2024-08-15T21:38:55.249894Z","shell.execute_reply.started":"2024-08-15T21:38:54.654329Z","shell.execute_reply":"2024-08-15T21:38:55.248964Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\nvocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.251066Z","iopub.execute_input":"2024-08-15T21:38:55.251395Z","iopub.status.idle":"2024-08-15T21:38:55.481873Z","shell.execute_reply.started":"2024-08-15T21:38:55.251368Z","shell.execute_reply":"2024-08-15T21:38:55.480638Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def selective_scan(u, delta, A, B, C, D):\n    # first step of A_bar = exp(ΔA), i.e., ΔA\n    dA = tf.einsum('bld,dn->bldn', delta, A) \n    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n    \n    dA_cumsum = tf.pad(\n        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n    \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n    \n    # Cumulative sum along all the input tokens, parallel prefix sum, \n    # calculates dA for all the input tokens parallely\n    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)  \n\n    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n    dA_cumsum = tf.exp(dA_cumsum)  \n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n\n    x = dB_u * dA_cumsum\n    # 1e-12 to avoid division by 0\n    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12) \n\n    y = tf.einsum('bldn,bln->bld', x, C)\n    \n    return y + u * D ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.483478Z","iopub.execute_input":"2024-08-15T21:38:55.484647Z","iopub.status.idle":"2024-08-15T21:38:55.500948Z","shell.execute_reply.started":"2024-08-15T21:38:55.484607Z","shell.execute_reply":"2024-08-15T21:38:55.499637Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class MambaBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        args = modelargs\n        self.layer_id = modelargs.layer_id\n\n        self.in_projection = layers.Dense(\n            args.model_internal_dim * 2, \n            input_shape=(args.model_input_dims,), use_bias=False)\n\n        self.conv1d = layers.Conv1D(\n            filters=args.model_internal_dim,\n            use_bias=args.conv_use_bias,\n            kernel_size=args.conv_kernel_size,\n            groups=args.model_internal_dim,\n            data_format='channels_first',\n            padding='causal'\n        )\n\n        # this layer takes in current token 'x' \n        # and outputs the input-specific Δ, B, C (according to S6)\n        self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n\n        # this layer projects Δ from delta_t_rank to the mamba internal \n        # dimension\n        self.delta_t_projection = layers.Dense(args.model_internal_dim, \n                                               input_shape=(args.delta_t_rank,), use_bias=True)\n\n        self.A = repeat(\n                tf.range(1, args.model_states+1, dtype=tf.float32), \n                'n -> d n', d=args.model_internal_dim)\n\n        self.A_log = tf.Variable(\n                tf.math.log(self.A), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_A_log_{args.layer_id}\")\n\n        self.D = tf.Variable(\n                np.ones(args.model_internal_dim), \n                trainable=True, dtype=tf.float32, \n                name=f\"SSM_D_{args.layer_id}\")\n\n        self.out_projection = layers.Dense(\n                args.model_input_dims, \n                input_shape=(args.model_internal_dim,), \n                use_bias=args.dense_use_bias)\n\n    def call(self, x):\n        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n        Official Implementation:\n            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n\n        (batch_size, seq_len, dimension) = x.shape\n\n        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n        (x, res) = tf.split(x_and_res, \n                            [self.args.model_internal_dim, \n                             self.args.model_internal_dim], axis=-1)\n        \n        x = rearrange(x, 'b l d_in -> b d_in l')\n        x = self.conv1d(x)[:, :, :seq_len]\n        x = rearrange(x, 'b d_in l -> b l d_in')\n        \n        x = tf.nn.swish(x)\n        y = self.ssm(x)\n        y = y * tf.nn.swish(res)\n        return self.out_projection(y)\n    \n    def ssm(self, x):\n        \"\"\"Runs the SSM. See:\n            - Algorithm 2 in Section 3.2 in the Mamba paper\n            - run_SSM(A, B, C, u) in The Annotated S4\n            Official Implementation:\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n        \"\"\"\n        (d_in, n) = self.A_log.shape\n\n        # Compute ∆ A B C D, the state space parameters.\n        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n        #                                  and is why Mamba is called **selective** state spaces)\n\n        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n        D = tf.cast(self.D, tf.float32)\n\n        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n\n        (delta, B, C) = tf.split(\n                x_dbl, \n                num_or_size_splits=[self.args.delta_t_rank, n, n], \n                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n\n        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n\n        return selective_scan(x, delta, A, B, C, D)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.502410Z","iopub.execute_input":"2024-08-15T21:38:55.502933Z","iopub.status.idle":"2024-08-15T21:38:55.527862Z","shell.execute_reply.started":"2024-08-15T21:38:55.502895Z","shell.execute_reply":"2024-08-15T21:38:55.526803Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.args = modelargs\n        self.mixer = MambaBlock(modelargs)\n        self.norm = layers.LayerNormalization(epsilon=1e-5)\n\n    def call(self, x):\n        \"\"\"\n        Official Implementation:\n            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n            \n            Note: the official repo chains residual blocks that look like\n                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n            where the first Add is a no-op. This is purely for performance reasons as this\n            allows them to fuse the Add->Norm.\n\n            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n            \n        \"\"\"\n        return self.mixer(self.norm(x)) + x","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.529582Z","iopub.execute_input":"2024-08-15T21:38:55.530011Z","iopub.status.idle":"2024-08-15T21:38:55.542317Z","shell.execute_reply.started":"2024-08-15T21:38:55.529978Z","shell.execute_reply":"2024-08-15T21:38:55.541503Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def init_model(args: ModelArgs):\n    input_layer = layers.Input(shape=(args.seq_length,), name='input_ids')\n    x = layers.Embedding(args.vocab_size, args.model_input_dims, input_length=args.seq_length)(input_layer)\n\n    for i in range(args.num_layers):\n        x = ResidualBlock(args, name=f\"Residual_{i}\")(x)\n        x = layers.Dropout(args.dropout_rate)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n    if not args.use_lm_head: # use flatten only if we are using the model as an LM\n        x = layers.Flatten()(x)\n    x = layers.Dense(1024, activation=tf.nn.gelu)(x)\n    output_layer = layers.Dense(args.num_classes, activation=args.final_activation)(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='MambaTimeModel')\n    model.compile(\n        loss=args.loss,\n        optimizer=args.optimizer,\n        metrics=args.metrics\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.545892Z","iopub.execute_input":"2024-08-15T21:38:55.546376Z","iopub.status.idle":"2024-08-15T21:38:55.556799Z","shell.execute_reply.started":"2024-08-15T21:38:55.546342Z","shell.execute_reply":"2024-08-15T21:38:55.556005Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"args = ModelArgs(\n    model_input_dims=max_seq_length,\n    model_states=32,\n    num_layers=12,\n    dropout_rate=0.2,\n    vocab_size=vocab_size\n)\nmodel = init_model(args)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:55.557680Z","iopub.execute_input":"2024-08-15T21:38:55.557949Z","iopub.status.idle":"2024-08-15T21:38:59.620610Z","shell.execute_reply.started":"2024-08-15T21:38:55.557926Z","shell.execute_reply":"2024-08-15T21:38:59.619925Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"MambaTimeModel\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_ids (InputLayer)      [(None, 128)]             0         \n                                                                 \n embedding (Embedding)       (None, 128, 128)          6432512   \n                                                                 \n Residual_0 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout (Dropout)           (None, 128, 128)          0         \n                                                                 \n Residual_1 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_1 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_2 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_2 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_3 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_3 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_4 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_4 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_5 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_5 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_6 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_6 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_7 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_7 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_8 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_8 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_9 (ResidualBlock)  (None, 128, 128)          129024    \n                                                                 \n dropout_9 (Dropout)         (None, 128, 128)          0         \n                                                                 \n Residual_10 (ResidualBlock  (None, 128, 128)          129024    \n )                                                               \n                                                                 \n dropout_10 (Dropout)        (None, 128, 128)          0         \n                                                                 \n Residual_11 (ResidualBlock  (None, 128, 128)          129024    \n )                                                               \n                                                                 \n dropout_11 (Dropout)        (None, 128, 128)          0         \n                                                                 \n layer_normalization_12 (La  (None, 128, 128)          256       \n yerNormalization)                                               \n                                                                 \n dense_48 (Dense)            (None, 128, 1024)         132096    \n                                                                 \n dense_49 (Dense)            (None, 128, 50254)        51510350  \n                                                                 \n=================================================================\nTotal params: 59623502 (227.45 MB)\nTrainable params: 59623502 (227.45 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom tqdm import tqdm\n\ndataset = load_dataset(\"neuralwork/fashion-style-instruct\", split=\"train[:1000]\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:38:59.621579Z","iopub.execute_input":"2024-08-15T21:38:59.621858Z","iopub.status.idle":"2024-08-15T21:39:01.171485Z","shell.execute_reply.started":"2024-08-15T21:38:59.621833Z","shell.execute_reply":"2024-08-15T21:39:01.170750Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.172652Z","iopub.execute_input":"2024-08-15T21:39:01.173016Z","iopub.status.idle":"2024-08-15T21:39:01.180222Z","shell.execute_reply.started":"2024-08-15T21:39:01.172982Z","shell.execute_reply":"2024-08-15T21:39:01.179276Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'completion', 'context'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token \nEOS_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.181301Z","iopub.execute_input":"2024-08-15T21:39:01.181572Z","iopub.status.idle":"2024-08-15T21:39:01.193169Z","shell.execute_reply.started":"2024-08-15T21:39:01.181547Z","shell.execute_reply":"2024-08-15T21:39:01.192312Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}]},{"cell_type":"code","source":"inputFormatString = \"\"\"You are a personal stylist recommending fashion advice and clothing combinations. Use the self body and style description below, combined with the event described in the context to generate 5 self-contained and complete outfit combinations.\n### Context:\n{}\n\n### Input:\n{}\"\"\"\n\noutputFormatString = \"\"\"### Completion:\n{}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.194259Z","iopub.execute_input":"2024-08-15T21:39:01.194549Z","iopub.status.idle":"2024-08-15T21:39:01.203278Z","shell.execute_reply.started":"2024-08-15T21:39:01.194525Z","shell.execute_reply":"2024-08-15T21:39:01.202456Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Define the function to create the new 'text' column\ndef formatDatasetAlpaca(sample):\n    context = sample['context']\n    inputText = sample['input']\n    completion = sample['completion']\n    \n    sampleInput = inputFormatString.format(context, inputText) + EOS_TOKEN\n    sampleOutput = outputFormatString.format(completion) + EOS_TOKEN\n    \n    sample['inputText'] = sampleInput\n    sample['outputText'] = sampleOutput\n    \n    return sample\n\n# Apply the function to the dataset\ndataset = dataset.map(formatDatasetAlpaca, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.204374Z","iopub.execute_input":"2024-08-15T21:39:01.204988Z","iopub.status.idle":"2024-08-15T21:39:01.216432Z","shell.execute_reply.started":"2024-08-15T21:39:01.204955Z","shell.execute_reply":"2024-08-15T21:39:01.215605Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.3)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.217558Z","iopub.execute_input":"2024-08-15T21:39:01.217847Z","iopub.status.idle":"2024-08-15T21:39:01.230282Z","shell.execute_reply.started":"2024-08-15T21:39:01.217823Z","shell.execute_reply":"2024-08-15T21:39:01.229410Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 700\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 300\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"pprint.pprint(dataset['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.231363Z","iopub.execute_input":"2024-08-15T21:39:01.231926Z","iopub.status.idle":"2024-08-15T21:39:01.238615Z","shell.execute_reply.started":"2024-08-15T21:39:01.231893Z","shell.execute_reply":"2024-08-15T21:39:01.237757Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'inputText': 'You are a personal stylist recommending fashion advice and '\n              'clothing combinations. Use the self body and style description '\n              'below, combined with the event described in the context to '\n              'generate 5 self-contained and complete outfit combinations.\\n'\n              '### Context:\\n'\n              'I usually go for jeans and tees with an edgy, androgynous look '\n              \"I'm going to a play / concert.\\n\"\n              '\\n'\n              '### Input:\\n'\n              \"I'm a tomboyish woman with big biceps and shoulders from \"\n              'weightlifting.<|endoftext|>',\n 'outputText': '### Completion:\\n'\n               'Outfit Combination 1:\\n'\n               '- Top: A fitted leather jacket with shoulder pads to enhance '\n               'your shoulders and give structure to the look.\\n'\n               '- Bottom: Black ripped skinny jeans for a edgy and rugged '\n               'touch.\\n'\n               '- Shoe: Black combat boots for a comfortable yet stylish '\n               'option.\\n'\n               '- Accessories: Chunky silver hoop earrings and a black studded '\n               'belt to complete the edgy look.\\n'\n               '\\n'\n               'Outfit Combination 2:\\n'\n               '- Top: A graphic band tee,\\n'\n               '- Bottom: High-waisted distressed denim shorts for a casual '\n               'and playful vibe.\\n'\n               '- Shoe: White sneakers for a cool and relaxed look.\\n'\n               '- Accessories: Layered silver necklaces and a black leather '\n               'backpack for a touch of accessorizing.\\n'\n               '\\n'\n               'Outfit Combination 3:\\n'\n               '- Top: A black oversized blazer, preferably with bold shoulder '\n               'pads, to make a statement.\\n'\n               '- Bottom: Fitted black leather pants for a sleek and polished '\n               'appearance.\\n'\n               '- Shoe: Pointed-toe heeled ankle boots in patent leather for '\n               'added glam.\\n'\n               '- Accessories: A silver choker and a structured black handbag '\n               'to complete the look.\\n'\n               '\\n'\n               'Outfit Combination 4:\\n'\n               '- Top: A white button-down shirt styled in a half-tuck for a '\n               'laid-back but chic vibe.\\n'\n               '- Bottom: Dark wash boyfriend jeans for a comfortable and '\n               'stylish look.\\n'\n               '- Shoe: White low-top sneakers for a classic and casual '\n               'touch.\\n'\n               '- Accessories: A black leather watch and a black fedora hat '\n               'for a touch of masculinity.\\n'\n               '\\n'\n               'Outfit Combination 5:\\n'\n               '- Top: A sleeveless muscle tank with a bold graphic print to '\n               'show off your biceps.\\n'\n               '- Bottom: High-waisted black joggers for a comfortable and '\n               'sporty look.\\n'\n               '- Shoe: White high-top sneakers for a cool and athletic vibe.\\n'\n               '- Accessories: Stackable bracelets and a sporty backpack for a '\n               'stylish and functional touch.\\n'\n               '<|endoftext|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.239668Z","iopub.execute_input":"2024-08-15T21:39:01.239965Z","iopub.status.idle":"2024-08-15T21:39:01.248982Z","shell.execute_reply.started":"2024-08-15T21:39:01.239941Z","shell.execute_reply":"2024-08-15T21:39:01.248152Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 700\n    })\n    test: Dataset({\n        features: ['inputText', 'outputText'],\n        num_rows: 300\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_texts = dataset['train']['inputText']\ntrain_completions = dataset['train']['outputText']\n\ntest_texts = dataset['test']['inputText']\ntest_completions = dataset['test']['outputText']","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.250126Z","iopub.execute_input":"2024-08-15T21:39:01.250539Z","iopub.status.idle":"2024-08-15T21:39:01.276697Z","shell.execute_reply.started":"2024-08-15T21:39:01.250506Z","shell.execute_reply":"2024-08-15T21:39:01.275954Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"np.shape(train_texts)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.278053Z","iopub.execute_input":"2024-08-15T21:39:01.278496Z","iopub.status.idle":"2024-08-15T21:39:01.286915Z","shell.execute_reply.started":"2024-08-15T21:39:01.278456Z","shell.execute_reply":"2024-08-15T21:39:01.285958Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(700,)"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding='max_length', max_length=max_seq_length)\ntrain_labels = tokenizer(train_completions, truncation=True, padding='max_length', max_length=max_seq_length)\n\ntest_encodings = tokenizer(test_texts, truncation=True, padding='max_length', max_length=max_seq_length)\ntest_labels = tokenizer(test_completions, truncation=True, padding='max_length', max_length=max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:01.287967Z","iopub.execute_input":"2024-08-15T21:39:01.288257Z","iopub.status.idle":"2024-08-15T21:39:02.033385Z","shell.execute_reply.started":"2024-08-15T21:39:01.288231Z","shell.execute_reply":"2024-08-15T21:39:02.032537Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"np.shape(train_encodings['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:02.034538Z","iopub.execute_input":"2024-08-15T21:39:02.034865Z","iopub.status.idle":"2024-08-15T21:39:02.050091Z","shell.execute_reply.started":"2024-08-15T21:39:02.034837Z","shell.execute_reply":"2024-08-15T21:39:02.048971Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(700, 128)"},"metadata":{}}]},{"cell_type":"code","source":"train_labels.keys()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:02.051234Z","iopub.execute_input":"2024-08-15T21:39:02.051543Z","iopub.status.idle":"2024-08-15T21:39:02.060760Z","shell.execute_reply.started":"2024-08-15T21:39:02.051517Z","shell.execute_reply":"2024-08-15T21:39:02.059928Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to TensorFlow Datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),  # input_ids and attention_mask\n    train_labels['input_ids']  # labels (target sequences)\n))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),  # input_ids and attention_mask\n    test_labels['input_ids']  # labels (target sequences)\n))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:02.061633Z","iopub.execute_input":"2024-08-15T21:39:02.061953Z","iopub.status.idle":"2024-08-15T21:39:03.222111Z","shell.execute_reply.started":"2024-08-15T21:39:02.061927Z","shell.execute_reply":"2024-08-15T21:39:03.221315Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Batch and shuffle the datasets\nBATCH_SIZE = 8\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:03.223193Z","iopub.execute_input":"2024-08-15T21:39:03.223486Z","iopub.status.idle":"2024-08-15T21:39:03.234932Z","shell.execute_reply.started":"2024-08-15T21:39:03.223460Z","shell.execute_reply":"2024-08-15T21:39:03.234093Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Print out the train dataset tensors; if you're insane\n# list(train_dataset.as_numpy_iterator())","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:03.235979Z","iopub.execute_input":"2024-08-15T21:39:03.236247Z","iopub.status.idle":"2024-08-15T21:39:03.241379Z","shell.execute_reply.started":"2024-08-15T21:39:03.236223Z","shell.execute_reply":"2024-08-15T21:39:03.240527Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = model.fit(train_dataset, validation_data=test_dataset, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T21:39:03.245512Z","iopub.execute_input":"2024-08-15T21:39:03.245790Z","iopub.status.idle":"2024-08-15T21:39:15.317318Z","shell.execute_reply.started":"2024-08-15T21:39:03.245764Z","shell.execute_reply":"2024-08-15T21:39:15.316480Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py:642: UserWarning: Input dict contained keys ['attention_mask'] which did not match any model input. They will be ignored by the model.\n  inputs = self._flatten_to_reference_inputs(inputs)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)","File \u001b[0;32m<timed exec>:1\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_613/1782677582.py\", line 9, in customBLEU  *\n        for true_seq, pred_seq in zip(y_true, y_pred):\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"],"ename":"OperatorNotAllowedInGraphError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_613/1782677582.py\", line 9, in customBLEU  *\n        for true_seq, pred_seq in zip(y_true, y_pred):\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n","output_type":"error"}]}]}